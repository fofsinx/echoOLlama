# ğŸ¦™ `echoOLlama`: Reverse-engineered OpenAIâ€™s [Realtime API]
> ğŸŒŸ Talk to your local LLM models in human voice and get responses in realtime!

![ğŸ¦™ EchoOLlama Banner](https://github.com/user-attachments/assets/d2422917-b03a-48aa-88c8-d40f0884bd5e)

> âš ï¸ **Active Development Alert!** âš ï¸
>
> We're cooking up something amazing! While the core functionality is taking shape, some features are still in the oven. Perfect for experiments, but maybe hold off on that production deployment for now! ğŸ˜‰

## ğŸ¯ What's `echoOLlama`?
`echoOLlama` is a cool project that lets you talk to AI models using your voice, just like you'd talk to a real person! ğŸ—£ï¸

Here's what makes it special:

- ğŸ¤ You can speak naturally and the AI understands you
- ğŸ¤– It works with local AI models (through Ollama) so your data stays private
- âš¡ Super fast responses in real-time
- ğŸ”Š The AI talks back to you with a natural voice
- ğŸ”„ Works just like OpenAI's API but with your own models

Think of it like having a smart assistant that runs completely on your computer. You can have natural conversations with it, ask questions, get help with tasks - all through voice! And because it uses local AI models, you don't need to worry about your conversations being stored in the cloud.

Perfect for developers who want to:
- Build voice-enabled AI applications
- Create custom AI assistants
- Experiment with local language models
- Have private AI conversations


### ğŸ‰ What's Working Now:

![ğŸ¦™ EchoOLlama Banner](https://github.com/user-attachments/assets/5ce20abf-6982-4b6b-a824-58f7d91ef7cd)

- âœ… Connection handling and session management
- âœ… Real-time event streaming
- âœ… Redis-based session storage
- âœ… Basic database interactions
- âœ… OpenAI compatibility layer
- âœ… Core WebSocket infrastructure

### ğŸš§ On the Roadmap:
- ğŸ“ Message processing pipeline (In Progress)
- ğŸ¤– Advanced response generation with client events
- ğŸ¯ Function calling implementation with client events
- ğŸ”Š Audio transcription service connection with client events
- ğŸ—£ï¸ Text-to-speech integration with client events
- ğŸ“Š Usage analytics dashboard
- ğŸ” Enhanced authentication system

## ğŸŒŸ Features & Capabilities

### ğŸ® Core Services
- **Real-time Chat** ğŸ’¬
  - Streaming responses via websockets
  - Multi-model support via Ollama
  - Session persistence
  - ğŸ¤ Audio Transcription (FASTER_Whisper)
  - ğŸ—£ï¸ Text-to-Speech (OpenedAI/Speech)

- **Coming Soon** ğŸ”œ
  - ğŸ”§ Function Calling System
  - ğŸ“Š Advanced Analytics

### ğŸ› ï¸ Technical Goodies
- âš¡ Lightning-fast response times
- ğŸ”’ Built-in rate limiting
- ğŸ“ˆ Usage tracking ready
- âš–ï¸ Load balancing for scale
- ğŸ¯ 100% OpenAI API compatibility



## ğŸ—ï¸ System Architecture

<a href='https://excalidraw.com/#json=FbCQY2ha_EX6w2CjqK6Mr,lWhsDsgEPXLsSELFBzBxqw' target='_blank'>
<img src='https://preview.redd.it/ollamagate-open-sourced-openai-v0-isuuo6mh7uyd1.png?width=2602&format=png&auto=webp&s=d497e1da5cd93874126e826ec3990a23e5339faa' alt='echoOLlama' />
</a>

> Click on the image to view the interactive version on Excalidraw!

## ğŸ’» Tech Stack Spotlight
### ğŸ¯ Backend Champions
- ğŸš€ FastAPI - Lightning-fast API framework
- ğŸ“ Redis - Blazing-fast caching & session management
- ğŸ˜ PostgreSQL - Rock-solid data storage

### ğŸ¤– AI Powerhouse
- ğŸ¦™ Ollama - Local LLM inference
- ğŸ¤ faster_whisper - Speech recognition (coming soon)
- ğŸ—£ï¸ OpenedAI TTS - Voice synthesis (coming soon)

## ğŸš€ Get Started in 3, 2, 1...

1. **Clone & Setup** ğŸ“¦
```bash
git clone https://github.com/iamharshdev/EchoOLlama.git
cd EchoOLlama
python -m venv .venv
source .venv/bin/activate  # or `.venv\Scripts\activate` on Windows
pip install -r requirements.txt
```

2. **Environment Setup** âš™ï¸
```bash
cp .env.example .env
# Update .env with your config - check .env.example for all options!
make migrate # create db and apply migrations
```

3. **Launch Time** ğŸš€
```bash
# Fire up the services
docker-compose up -d

# Start the API server
uvicorn app.main:app --reload
```

## ğŸ¤ Join the EchoOLlama Family
Got ideas? Found a bug? Want to contribute? Check out our [CONTRIBUTING.md](CONTRIBUTING.md) guide and become part of something awesome! We love pull requests! ğŸ‰

## ğŸ’¡ Project Status Updates
- ğŸŸ¢ **Working**: Connection handling, session management, event streaming
- ğŸŸ¡ **In Progress**: Message processing, response generation
- ğŸ”´ **Planned**: Audio services, function calling, analytics

## ğŸ“œ License
MIT Licensed - Go wild! See [LICENSE](LICENSE) for the legal stuff.

---
*Built with ğŸ’– by the community, for the community*

*PS: Star â­ us on GitHub if you like what we're building!*
